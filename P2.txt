1. Create an empty data frame - 
val df = spark.emptyDataFrame
df.printSchema()

2. Create empty data set - 
case class Name(firstName: String, lastName: String, middleName:String)
val ds1 = spark.emptyDataset[Empty]
ds1.printSchema()
// createDataset() â€“ Create Empty Dataset with schema
val ds2=spark.createDataset(Seq.empty[Name])
ds2.printSchema()

3.4.5.6 Use of Rename nested column,Adding or Updating a column on DataFrame, Drop a column on DataFrame, Adding literal constant to DataFrame -  
Changing column data type- 
import org.apache.spark.sql.{Row, SparkSession}
import org.apache.spark.sql.types.{StringType, StructType}
import org.apache.spark.sql.functions._
val dataRows = Seq(
      Row(Row("James;","","Smith"),"36636","M","3000"),
      Row(Row("Michael","Rose",""),"40288","M","4000"),
      Row(Row("Robert","","Williams"),"42114","M","4000"),
      Row(Row("Maria","Anne","Jones"),"39192","F","4000"),
      Row(Row("Jen","Mary","Brown"),"","F","-1")
    )
 
val schema = new StructType().add("name",new StructType().add("firstname",StringType).add("middlename",StringType).add("lastname",StringType)).add("dob",StringType).add("gender",StringType).add("salary",StringType)
 
val df2 = spark.createDataFrame(spark.sparkContext.parallelize(dataRows),schema)
df2.printSchema()

//Change the column data type
var newdf=df2.withColumn("salary",df2("salary").cast("Integer"))
//Derive a new column from existing
val df4=newdf.withColumn("CopiedColumn",newdf("salary")* -1)
//Renaming a column
val df3=newdf.withColumnRenamed("gender","sex")
//Dropping a column
val df6=df4.drop("CopiedColumn")
//Adding a literal value
newdf.withColumn("Country", lit("USA")).printSchema()

8. Pivot and Unpivot a data frame - 
//Pivot 
val data = Seq(("Banana",1000,"USA"),("Carrots",2000,"Canada"),("Beans",2000,"Mexico"))
val df = data.toDF("Product","Amount","Country") 
df.show()
val pivotDF = df.groupBy("Product").pivot("Country").sum("Amount")
pivotDF.show()
//Unpivot 
val unPivotDF = pivotDF.select($"Product",
expr("stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)")).where("Total is not null")
unPivotDF.show()

9. Create a DataFrame using StructType & StructField schema
val simpleData = Seq(Row("James","Smith","36636","M"),
 Row("Maria ","Anne","Jones","39192","F"))
val simpleSchema = StructType(Array(
 StructField("firstname",StringType,true),
 StructField("lastname",StringType,true),
 StructField("id", StringType, true),
 StructField("gender", StringType, true),
 ))
val df = spark.createDataFrame(spark.sparkContext.parallelize(simpleData),simpleSchema)
df.printSchema()
df.show()

1. Selecting the first row of each group
